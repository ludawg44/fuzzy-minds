# Chapter 7 Ensemble Learning and Random Forests

- [Voting Classifiers](#voting-classifiers)
- [Bagging and Pasting](#bagging-and-pasting)
- [Bagging and Pasting in Scikit-Learn](#bagging-and-pasting-in-scikit-learn)
- [Out-of-Bag Evaluation](#out-of-bag-evaluation)
- [Random Patches and Random Subspaces](#random-patches-and-random-subspaces)
- [Random Forests](#random-forests)
- [Extra-Trees](#extra-trees)
- [Feature Importance](#feature-importance)
- [Boosting](#boosting)
- [AdaBoost](#adaboost)
- [Gradient Boosting](#gradient-boosting)
- [Stacking](#stacking)

Key vocabulary:
- ensemble: a group of dictors
- [Ensemble Learning](https://en.wikipedia.org/wiki/Ensemble_learning): In statistics and machine learning, ensemble methods use multiple learning algorithms to obtain better predictive performance than could be obtained from any of the constituent learning algorithms alone. 
- [Random Forest](https://en.wikipedia.org/wiki/Random_forest): an ensemble learning method for classification, regression and other tasks that operate by constructing a multitude of decision trees at training time and outputting the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees
- bagging: 
- boosting: 
- stacking: 

## Voting Classifiers

## Bagging and Pasting

## Bagging and Pasting in Scikit-Learn

## Out-of-bag Evaluation

## Random Patches and Random Subspaces

## Random Forests

## Extra Trees

## Feature Importance

## Boosting

## AdaBoost

## Gradient Boosting

## Stacking 
